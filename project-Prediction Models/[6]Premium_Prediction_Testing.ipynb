{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e46c7a83-685c-4725-83ba-2d226fd5383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------IMPORTS---------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import psycopg2\n",
    "from datetime import datetime, timedelta\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import Table, MetaData\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, classification_report\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a230e781-78f8-467f-b18c-a5e236de94c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ananya.datta\\AppData\\Local\\Temp\\ipykernel_18596\\2782923281.py:130: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  dff = pd.read_sql_query(query, connection)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Fetched Successfully!\n"
     ]
    }
   ],
   "source": [
    "# --- MAIN EXECUTION ---\n",
    "query =\"\"\"SELECT \n",
    "        p.policy_no,\n",
    "        p.inception_date_new,\n",
    "        p.expiry_date,\n",
    "        p.split,\n",
    "        p.sum_insured,\n",
    "        p.branch,\n",
    "        p.cust_type,\n",
    "        p.cust_post_code,\n",
    "        p.cust_gender,\n",
    "        p.cust_age,\n",
    "        p.vehicle_age,\n",
    "        p.make,\n",
    "        p.model,\n",
    "        p.cc,\n",
    "        p.cust_state,\n",
    "        p.xc_veh_renewal_no,\n",
    "        p.ncb_perc,\n",
    "        p.pref_segment,\n",
    "        0::numeric AS GWP,\n",
    "        SUM(p.gic) AS GIC,\n",
    "        SUM(p.noc_total) AS noc_total\n",
    "    FROM ads.fct_mot_clm p\n",
    "    LEFT JOIN ADS.MST_CONTRACT_TYPE c1\n",
    "        ON p.CONTRACT_TYPE = c1.CONTRACT_TYPE_CODE\n",
    "    INNER JOIN (\n",
    "        SELECT * \n",
    "        FROM ADS.CTL_CALENDAR \n",
    "        WHERE CALENDAR_DT = (\n",
    "            SELECT MAX(CALENDAR_DT) \n",
    "            FROM ADS.CTL_CALENDAR \n",
    "            WHERE STATUS = 'SUCCESS'\n",
    "        )\n",
    "    ) c ON p.uw_date >= DATE '2025-05-01'\n",
    "    WHERE \n",
    "        c1.CONTRACT_TYPE_LONG_DESC ILIKE '%PRIVATE CAR%' AND \n",
    "        p.cover = 'CO'\n",
    "    GROUP BY \n",
    "        p.policy_no,\n",
    "        p.inception_date_new,\n",
    "        p.expiry_date,\n",
    "        p.split,\n",
    "        p.sum_insured,\n",
    "        p.branch,\n",
    "        p.cust_type,\n",
    "        p.cust_post_code,\n",
    "        p.cust_gender,\n",
    "        p.cust_age,\n",
    "        p.vehicle_age,\n",
    "        p.make,\n",
    "        p.model,\n",
    "        p.cc,\n",
    "        p.cust_state,\n",
    "        p.xc_veh_renewal_no,\n",
    "        p.ncb_perc,\n",
    "        p.pref_segment\n",
    "    \n",
    "    UNION ALL\n",
    "\n",
    "    SELECT \n",
    "        p.policy_no,\n",
    "        p.inception_date_final,\n",
    "        p.expiry_date,\n",
    "        p.split,\n",
    "        p.sum_insured,\n",
    "        p.branch,\n",
    "        p.cust_type,\n",
    "        p.cust_post_code,\n",
    "        p.cust_gender,\n",
    "        p.cust_age,\n",
    "        p.vehicle_age,\n",
    "        p.make,\n",
    "        p.model,\n",
    "        p.cc,\n",
    "        p.cust_state,\n",
    "        p.xc_veh_renewal_no,\n",
    "        p.ncb_perc,\n",
    "        p.pref_segment,\n",
    "        SUM(p.gwp) AS GWP,\n",
    "        0::numeric AS GIC,\n",
    "        0::numeric AS noc_total\n",
    "    FROM ads.fct_mot_pol p\n",
    "    LEFT JOIN ADS.MST_CONTRACT_TYPE c1\n",
    "        ON p.CONTRACT_TYPE = c1.CONTRACT_TYPE_CODE\n",
    "    INNER JOIN (\n",
    "        SELECT * \n",
    "        FROM ADS.CTL_CALENDAR \n",
    "        WHERE CALENDAR_DT = (\n",
    "            SELECT MAX(CALENDAR_DT) \n",
    "            FROM ADS.CTL_CALENDAR \n",
    "            WHERE STATUS = 'SUCCESS'\n",
    "        )\n",
    "    ) c ON p.uw_date >= DATE '2025-05-01'\n",
    "    WHERE \n",
    "        c1.CONTRACT_TYPE_LONG_DESC ILIKE '%PRIVATE CAR%' AND \n",
    "        p.cover = 'CO'\n",
    "    GROUP BY \n",
    "        p.policy_no,\n",
    "        p.inception_date_final,\n",
    "        p.expiry_date,\n",
    "        p.split,\n",
    "        p.sum_insured,\n",
    "        p.branch,\n",
    "        p.cust_type,\n",
    "        p.cust_post_code,\n",
    "        p.cust_gender,\n",
    "        p.cust_age,\n",
    "        p.vehicle_age,\n",
    "        p.make,\n",
    "        p.model,\n",
    "        p.cc,\n",
    "        p.cust_state,\n",
    "        p.xc_veh_renewal_no,\n",
    "        p.ncb_perc,\n",
    "        p.pref_segment;  \n",
    "        ;\"\"\"\n",
    "# --- DB CONNECTION ---\n",
    "try:\n",
    "    connection = psycopg2.connect(\n",
    "        host = \"172.16.10.212\",\n",
    "        dbname = \"PIB_PRD\",\n",
    "        user = \"usr_app_pdi\",\n",
    "        password = 'Usr@ppPd!#123',\n",
    "        port = \"5432\"\n",
    "    )\n",
    "    print(\"Connected to the database\")\n",
    "\n",
    "    cursor = connection.cursor()\n",
    "    dff = pd.read_sql_query(query, connection)\n",
    "    print(\"DataFrame Fetched Successfully!\")\n",
    "    # print(dff.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error: Unable to connect to the database\")\n",
    "    print(e)\n",
    "\n",
    "# finally:\n",
    "#     # Close the cursor and connection\n",
    "#     if cursor:\n",
    "#         cursor.close()\n",
    "#     if connection:\n",
    "#         connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b8ea818f-3526-43ad-b3ea-93f2a4ac2d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------Trial purposes-------\n",
    "dff.to_csv('POLNCLAIM_27-06.csv',index = False)\n",
    "dff = pd.read_csv(r'C:\\Users\\ananya.datta\\OneDrive - Fairfax Asia Ltd\\Desktop\\Project 1 - Predictive Premium Pricing Modelling\\Notebooks.py\\POLNCLAIM_27-06.csv')\n",
    "# dff = pd.read_csv(r'C:\\Users\\ananya.datta\\OneDrive - Fairfax Asia Ltd\\Desktop\\Project 1 - Predictive Premium Pricing Modelling\\Notebooks.py\\POLNCLAIM_11-06.csv')\n",
    "# dff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b4435037-d4d7-49b2-b1ac-0fc4af16392c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26690, 21)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff.shape\n",
    "# dff.inception_date_new.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c763953-eafb-4e24-94bd-d2f09be81ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dff.copy()\n",
    "# df = df[df['inception_date_new'] > '2025-04-30']\n",
    "df = df.groupby(['policy_no','inception_date_new','expiry_date','split']).agg({\n",
    "    'gwp': 'sum',          \n",
    "    'sum_insured': 'sum',  \n",
    "    'gic': 'sum',          \n",
    "    'noc_total': 'sum',    \n",
    "    'branch': 'first',     \n",
    "    'cust_type': 'first',  \n",
    "    'cust_post_code': 'first',  \n",
    "    'cust_state': 'first', \n",
    "    'cust_gender': 'first', \n",
    "    'cust_age': 'first',   \n",
    "    'vehicle_age': 'first', \n",
    "    'make': 'first',      \n",
    "    'model': 'first',      \n",
    "    'cc': 'first',         \n",
    "    'xc_veh_renewal_no': 'first', \n",
    "    'ncb_perc': 'first',  \n",
    "    'pref_segment': 'first' }).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "42f0b25f-fdb3-49d8-98ad-85ed230ca3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_cc(f):\n",
    "    # Define the bins and labels\n",
    "    bins = [0, 1000, 1500, 2000, 3000, 4000, np.inf]\n",
    "    labels = ['0-1000', '1000-1500', '1500-2000', '2000-3000', '3000-4000', '4000+']\n",
    "    \n",
    "    # Apply the categorization to the 'cc' column using pd.cut\n",
    "    f['cc'] = pd.cut(f['cc'], bins=bins, labels=labels, right=False)\n",
    "    \n",
    "    return f\n",
    "    \n",
    "def process_cust_age(f, lowerb=20, upperb=80):\n",
    "    # Cap and floor bounds for 'cust_age'\n",
    "    f['cust_age'] = f['cust_age'].apply(lambda x: max(min(x, upperb), lowerb))\n",
    "    \n",
    "    # Fill the missing values with the sampled values\n",
    "    missing_indices = f[f['cust_age'].isnull()].index\n",
    "    non_missing_values = f['cust_age'].dropna()  # Get non-null values\n",
    "    random_samples = np.random.choice(non_missing_values, size=len(missing_indices), replace=True)\n",
    "    f.loc[missing_indices, 'cust_age'] = random_samples\n",
    "    return f\n",
    "\n",
    "def process_cust_gender(f):\n",
    "     # Calculate the proportions of 'M' and 'F' in the entire dataset\n",
    "    f['cust_gender'] = f['cust_gender'].replace([''], np.nan)\n",
    "    gender_counts = f['cust_gender'].value_counts(normalize=True)\n",
    "    prob_m = gender_counts.get('M', 0)  # Proportion of 'M'\n",
    "    prob_f = gender_counts.get('F', 0)  # Proportion of 'F'\n",
    "    # Make sure the probabilities sum to 1\n",
    "    total_prob = prob_m + prob_f\n",
    "    if total_prob != 1:\n",
    "        prob_m /= total_prob\n",
    "        prob_f /= total_prob\n",
    "    # Define the imputation function\n",
    "    def fill_gender(row):\n",
    "        if pd.isna(row['cust_gender']):\n",
    "            # Sample a gender based on the overall proportions\n",
    "            return np.random.choice(['M', 'F'], p=[prob_m, prob_f])\n",
    "        return row['cust_gender']\n",
    "    f['cust_gender'] = f.apply(fill_gender, axis=1)\n",
    "    return f\n",
    "\n",
    "def process_model(f, top_n=10):\n",
    "    # Get the top N most frequent models\n",
    "    model_distribution = f['model'].dropna().value_counts()\n",
    "    top_n_models = model_distribution.head(top_n)\n",
    "    model_proportions = top_n_models / top_n_models.sum()\n",
    "    # Generate a list of model values to fill in the missing 'model' entries, proportionally\n",
    "    missing_indices = f[f['model'].isnull()].index\n",
    "    # Sample from the top N models using the calculated proportions\n",
    "    fill_values = np.random.choice(top_n_models.index, size=len(missing_indices), p=model_proportions)\n",
    "    # Fill the missing values in the 'model' column\n",
    "    f.loc[missing_indices, 'model'] = fill_values\n",
    "\n",
    "    return f\n",
    "\n",
    "def process_make(f, top_n=10):\n",
    "    # Get the top N most frequent models\n",
    "    make_distribution = f['make'].dropna().value_counts()\n",
    "    top_n_make = make_distribution.head(top_n)\n",
    "    make_proportions = top_n_make / top_n_make.sum()\n",
    "    # Generate a list of model values to fill in the missing 'model' entries, proportionally\n",
    "    missing_indices = f[f['make'].isnull()].index\n",
    "    # Sample from the top N models using the calculated proportions\n",
    "    fill_values = np.random.choice(top_n_make.index, size=len(missing_indices), p=make_proportions)\n",
    "    # Fill the missing values in the 'model' column\n",
    "    f.loc[missing_indices, 'make'] = fill_values\n",
    "\n",
    "    return f\n",
    "\n",
    "def process_postcode(f, top_n=10):\n",
    "    # Get the top N most frequent models\n",
    "    postcode_distribution = f['cust_post_code'].dropna().value_counts()\n",
    "    top_n_postcode = postcode_distribution.head(top_n)\n",
    "    postcode_proportions = top_n_postcode / top_n_postcode.sum()\n",
    "    # Generate a list of model values to fill in the missing 'model' entries, proportionally\n",
    "    missing_indices = f[f['cust_post_code'].isnull()].index\n",
    "    # Sample from the top N models using the calculated proportions\n",
    "    fill_values = np.random.choice(top_n_postcode.index, size=len(missing_indices), p=postcode_proportions)\n",
    "    # Fill the missing values in the 'model' column\n",
    "    f.loc[missing_indices, 'cust_post_code'] = fill_values\n",
    "\n",
    "    return f\n",
    "\n",
    "def process_lossratio(f):\n",
    "    # Calculate the 'loss_ratio' column\n",
    "    f['loss_ratio'] = f.apply(lambda row: 'not there' if row['gic'] == 0 and row['gwp'] == 0 \n",
    "                              else 0 if row['gic'] == 0 \n",
    "                              else 'not defined' if row['gwp'] == 0 \n",
    "                              else row['gic'] / row['gwp'], axis=1)\n",
    "    \n",
    "    # Remove rows where 'loss_ratio' is 'not there' or 'not defined'\n",
    "    f = f[~f['loss_ratio'].isin(['not there', 'not defined'])]\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e748810c-9ee7-4911-ab99-6daa9b24ba66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process_cust_age(df)\n",
    "df = process_cust_gender(df)\n",
    "df = process_model(df)\n",
    "df = process_make(df)\n",
    "df = process_postcode(df)\n",
    "df = process_lossratio(df)\n",
    "df = categorize_cc(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85736be4-f605-43aa-8dc1-4f17fab66306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_preprocess(df):\n",
    "    if not np.issubdtype(df['inception_date_new'].dtype, np.datetime64):\n",
    "        df['inception_date_new'] = pd.to_datetime(df['inception_date_new'])\n",
    "    df['inception_year'] = df['inception_date_new'].dt.year\n",
    "    df['loss_ratio'] = df['loss_ratio'].astype('int64')\n",
    "    df = df[df['branch'] != 'H5']\n",
    "    return df\n",
    "\n",
    "def extract_date_parts(df):\n",
    "    if not np.issubdtype(df['inception_date_new'].dtype, np.datetime64):\n",
    "        df['inception_date_new'] = pd.to_datetime(df['inception_date_new'])\n",
    "    df['inception_month'] = df['inception_date_new'].dt.month\n",
    "    df['inception_year'] = df['inception_date_new'].dt.year\n",
    "    df = df.sort_values('inception_date_new')\n",
    "    return df\n",
    "\n",
    "def preserve_original(df, cols):\n",
    "    return df[cols].copy()\n",
    "\n",
    "def drop_unnecessary_columns(df, cols_to_drop):\n",
    "    return df.drop(cols_to_drop, axis=1)\n",
    "\n",
    "def convert_dtypes_for_catboost(df, convert_float_to_int=True):\n",
    "    df[\"inception_year\"] = df[\"inception_year\"].astype('int64')\n",
    "    df[\"inception_month\"] = df[\"inception_month\"].astype('int64')\n",
    "    df[\"cc\"] = df[\"cc\"].astype('object')\n",
    "    return df \n",
    "\n",
    "def prepare_data(df, preserve_cols, drop_cols, convert_float_to_int=True):\n",
    "    preserved_df = preserve_original(df, preserve_cols)\n",
    "    df = drop_unnecessary_columns(df, drop_cols)\n",
    "    df = convert_dtypes_for_catboost(df, convert_float_to_int=convert_float_to_int)\n",
    "    return df, preserved_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c7a73ba2-4c92-43e8-aa17-7987cd57d628",
   "metadata": {},
   "outputs": [],
   "source": [
    "preserve_cols = ['policy_no', 'inception_date_new', 'expiry_date', 'noc_total']\n",
    "drop_cols = ['policy_no', 'inception_date_new', 'expiry_date', 'noc_total']\n",
    "\n",
    "# testing dataframe\n",
    "tst1 = initial_preprocess(df)\n",
    "tst1 = extract_date_parts(df)\n",
    "tst1, tst1_og = prepare_data(tst1, preserve_cols, drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "79cbea3f-7ec5-484f-8c28-c74bc783ed8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gwp'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def categorize_columns_for_catboost(df):\n",
    "    num = []\n",
    "    cat = []\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype in ['int64', 'float64']:  # For numerical columns\n",
    "            num.append(column)\n",
    "            if df[column].dtype == 'float64':  # Convert float to int\n",
    "                df[column] = df[column].astype(np.int64)\n",
    "        elif df[column].dtype == 'object':  # For categorical columns (string type)\n",
    "            cat.append(column)\n",
    "    \n",
    "    return num, cat\n",
    "\n",
    "numerical,categorical = categorize_columns_for_catboost(tst1)\n",
    "numerical.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6bc284ba-5d36-45cf-90cc-9731ddc9bbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x1d007a6fe90>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2f723dff-5c1f-4847-8db8-e486ede1c3b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x1d01be69af0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of the model\n",
    "best_model = CatBoostRegressor()\n",
    "best_model.load_model('catboostRegressorfinal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cb39d3db-7b84-4b00-a152-1ce921295e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "policy_no              object\n",
       "inception_date_new     object\n",
       "expiry_date            object\n",
       "split                  object\n",
       "sum_insured           float64\n",
       "branch                 object\n",
       "cust_type              object\n",
       "cust_post_code          int64\n",
       "cust_gender            object\n",
       "cust_age              float64\n",
       "vehicle_age           float64\n",
       "make                   object\n",
       "model                  object\n",
       "cc                    float64\n",
       "cust_state             object\n",
       "xc_veh_renewal_no       int64\n",
       "ncb_perc              float64\n",
       "pref_segment            int64\n",
       "gwp                   float64\n",
       "gic                   float64\n",
       "noc_total             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eeaedc6f-2208-4b49-bffd-a35419146a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_merge(model, df, df_og, numerical_columns, categorical_columns, target_col='gwp'):\n",
    "    # Prepare the features (X) and target (y)\n",
    "    X = df[numerical_columns + categorical_columns]\n",
    "    y = df[target_col]\n",
    "\n",
    "    # Make predictions (without passing 'cat_features')\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    # Assign the predicted values to the dataframe\n",
    "    df = df.assign(predicted_gwp=y_pred)\n",
    "\n",
    "    # Convert 'inception_date_new' to object type in the original dataframe\n",
    "    df_og['inception_date_new'] = df_og['inception_date_new'].astype('object')\n",
    "\n",
    "    # Merge the original dataframe with the predictions\n",
    "    df = df_og.merge(df, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    # Convert 'inception_date_new' back to datetime format\n",
    "    df['inception_date_new'] = pd.to_datetime(df['inception_date_new']).dt.date\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the function to tst1\n",
    "tst1 = predict_and_merge(best_model, tst1, tst1_og, numerical, categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71d33f71-7f74-4dcf-b93f-a025c1c2942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tst1[categorical].dtypes)\n",
    "# tst1.split.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d489e4ea-264d-4b63-8685-a19f6cc07210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in categorical:\n",
    "#     print(f\"Unique values in {col}: {tst1[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf7b8dc4-e645-4d2b-a2bc-caf1aa708b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check the dataframe for rows containing 'NONACT'\n",
    "# problematic_rows = tst1[tst1.apply(lambda row: row.astype(str).str.contains('NONACT').any(), axis=1)]\n",
    "# problematic_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "96b6daeb-5ac8-4235-a57f-d49f193adec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>policy_no</th>\n",
       "      <th>inception_date_new</th>\n",
       "      <th>expiry_date</th>\n",
       "      <th>noc_total</th>\n",
       "      <th>split</th>\n",
       "      <th>gwp</th>\n",
       "      <th>sum_insured</th>\n",
       "      <th>gic</th>\n",
       "      <th>branch</th>\n",
       "      <th>cust_type</th>\n",
       "      <th>...</th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>cc</th>\n",
       "      <th>xc_veh_renewal_no</th>\n",
       "      <th>ncb_perc</th>\n",
       "      <th>pref_segment</th>\n",
       "      <th>loss_ratio</th>\n",
       "      <th>inception_year</th>\n",
       "      <th>inception_month</th>\n",
       "      <th>predicted_gwp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11705</th>\n",
       "      <td>V7205347</td>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>2026-04-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ACT</td>\n",
       "      <td>329</td>\n",
       "      <td>20700</td>\n",
       "      <td>0</td>\n",
       "      <td>T1</td>\n",
       "      <td>P</td>\n",
       "      <td>...</td>\n",
       "      <td>ISUZU</td>\n",
       "      <td>D MAX</td>\n",
       "      <td>2000-3000</td>\n",
       "      <td>7</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025</td>\n",
       "      <td>5</td>\n",
       "      <td>212.875480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5015</th>\n",
       "      <td>V6765758</td>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>2026-04-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONACT</td>\n",
       "      <td>472</td>\n",
       "      <td>12900</td>\n",
       "      <td>0</td>\n",
       "      <td>W8</td>\n",
       "      <td>P</td>\n",
       "      <td>...</td>\n",
       "      <td>TOYOTA</td>\n",
       "      <td>VIOS</td>\n",
       "      <td>1000-1500</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025</td>\n",
       "      <td>5</td>\n",
       "      <td>290.455670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014</th>\n",
       "      <td>V6765758</td>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>2026-04-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ACT</td>\n",
       "      <td>187</td>\n",
       "      <td>12900</td>\n",
       "      <td>0</td>\n",
       "      <td>W8</td>\n",
       "      <td>P</td>\n",
       "      <td>...</td>\n",
       "      <td>TOYOTA</td>\n",
       "      <td>VIOS</td>\n",
       "      <td>1000-1500</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025</td>\n",
       "      <td>5</td>\n",
       "      <td>151.302975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4963</th>\n",
       "      <td>V6762151</td>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>2026-04-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NONACT</td>\n",
       "      <td>373</td>\n",
       "      <td>18100</td>\n",
       "      <td>0</td>\n",
       "      <td>J1</td>\n",
       "      <td>P</td>\n",
       "      <td>...</td>\n",
       "      <td>TOYOTA</td>\n",
       "      <td>CAMRY</td>\n",
       "      <td>1500-2000</td>\n",
       "      <td>4</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2025</td>\n",
       "      <td>5</td>\n",
       "      <td>310.951137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4962</th>\n",
       "      <td>V6762151</td>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>2026-04-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ACT</td>\n",
       "      <td>316</td>\n",
       "      <td>18100</td>\n",
       "      <td>0</td>\n",
       "      <td>J1</td>\n",
       "      <td>P</td>\n",
       "      <td>...</td>\n",
       "      <td>TOYOTA</td>\n",
       "      <td>CAMRY</td>\n",
       "      <td>1500-2000</td>\n",
       "      <td>4</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2025</td>\n",
       "      <td>5</td>\n",
       "      <td>191.217097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      policy_no inception_date_new expiry_date  noc_total   split  gwp  \\\n",
       "11705  V7205347         2025-05-01  2026-04-30        0.0     ACT  329   \n",
       "5015   V6765758         2025-05-01  2026-04-30        0.0  NONACT  472   \n",
       "5014   V6765758         2025-05-01  2026-04-30        0.0     ACT  187   \n",
       "4963   V6762151         2025-05-01  2026-04-30        0.0  NONACT  373   \n",
       "4962   V6762151         2025-05-01  2026-04-30        0.0     ACT  316   \n",
       "\n",
       "       sum_insured  gic branch cust_type  ...    make  model         cc  \\\n",
       "11705        20700    0     T1         P  ...   ISUZU  D MAX  2000-3000   \n",
       "5015         12900    0     W8         P  ...  TOYOTA   VIOS  1000-1500   \n",
       "5014         12900    0     W8         P  ...  TOYOTA   VIOS  1000-1500   \n",
       "4963         18100    0     J1         P  ...  TOYOTA  CAMRY  1500-2000   \n",
       "4962         18100    0     J1         P  ...  TOYOTA  CAMRY  1500-2000   \n",
       "\n",
       "       xc_veh_renewal_no  ncb_perc pref_segment loss_ratio inception_year  \\\n",
       "11705                  7        55            0          0           2025   \n",
       "5015                   2        55            0          0           2025   \n",
       "5014                   2        55            0          0           2025   \n",
       "4963                   4        55            3          0           2025   \n",
       "4962                   4        55            3          0           2025   \n",
       "\n",
       "       inception_month  predicted_gwp  \n",
       "11705                5     212.875480  \n",
       "5015                 5     290.455670  \n",
       "5014                 5     151.302975  \n",
       "4963                 5     310.951137  \n",
       "4962                 5     191.217097  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst1.columns\n",
    "tst1.head()\n",
    "# tst1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9942ad5-72a1-4c51-b6b7-fadd4b84c3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DATABASE CONNECTION AND UPLOAD ---\n",
    "# Define the database connection parameters\n",
    "host = \"172.16.10.212\"\n",
    "dbname = \"PIB_PRD\"\n",
    "user = \"usr_app_pdi\"\n",
    "password = 'Usr@ppPd!#123'\n",
    "port = \"5432\"  # Default is 5432\n",
    "\n",
    "# Safely encode credentials\n",
    "safe_user = quote_plus(user)\n",
    "safe_password = quote_plus(password)\n",
    "\n",
    "# Build connection string\n",
    "connection_string = f'postgresql+psycopg2://{safe_user}:{safe_password}@{host}:{port}/{dbname}'\n",
    "engine = create_engine(connection_string)\n",
    "tst1.to_sql('pol_clm_gwp_prediction_May25', engine, schema='ads', if_exists='replace', index=False)\n",
    "print(\"Dataframe uploaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d5ab9f-a6f0-4398-b1c9-c6070b2c824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cursor:\n",
    "    cursor.close()\n",
    "if connection:\n",
    "    connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
